{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[ 5 pts] 1. [ 5 pts] Load the two datasets into pandas\n",
    "#Also loaded all necessary libraries for later use as well. If kernel must be restarded, \n",
    "#or values in crimeSet/vacantSet are unexpected, re-run this module.\n",
    "\n",
    "\n",
    "#MALIK MONTAY JACKSON\n",
    "#Print statements are commented to save you a barrage of prints from every module, uncomment each to see functionality related\n",
    "#to hw\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas \n",
    "from scipy.stats import mstats\n",
    "import time\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "crimeSet = pandas.read_csv('Crime_Data.csv')\n",
    "vacantSet = pandas.read_csv('Vacant_Buildings.csv')\n",
    "\n",
    "#print(crimeSet) \n",
    "#print(vacantSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2. [10 pts] Identify the types of the attributes in the two datasets (nominal, numeric, ratio,\n",
    "#intervals, etc); gather this information in a “metadata” panda.\n",
    "#Most data here is categorical and cannot be ranked. Exception are the Crime Dates which are times. vacantset'sLocation,\n",
    "#may also be considered Numeric: Ratio Scaled (Since we can define 0 in coordinates) if we consider xy y coodinartes as ranked \n",
    "\n",
    "#print (crimeSet) #We know the type of our data based on what we see here.\n",
    "crimeSet.metadata_CrimeDate = \"Numeric: Interval Scaled\"\n",
    "crimeSet.metadata_CrimeCode = \"Nominal\"\n",
    "crimeSet.metadata_Location = \"Nominal\"\n",
    "crimeSet.metadata_Description = \"Nominal\"\n",
    "crimeSet.metadata_Weapon = \"Nominal\"\n",
    "crimeSet.metadata_District = \"Nominal\"\n",
    "crimeSet.metadata_Neighborhood = \"Nominal\"\n",
    "\n",
    "#print (vacantSet) #We know the type of our data based on what we see here.\n",
    "\n",
    "vacantSet.metadata_ReferenceID = \"Nominal\"\n",
    "vacantSet.metadata_Block = \"Nominal\"\n",
    "vacantSet.metadata_Lot = \"Nominal\"\n",
    "vacantSet.metadata_BuildingAddress = \"Nominal\"\n",
    "vacantSet.metadata_NoticeDate = \"Numeric: Interval Scaled\"\n",
    "vacantSet.metadata_Neighborhood = \"Nominal\"\n",
    "vacantSet.metadata_PoliceDistrict = \"Nominal\"\n",
    "vacantSet.metadata_CouncilDistrict = \"Nominal\"\n",
    "vacantSet.metadata_Location = \"Numeric: Ratio Scaled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3. [30 pts] Demonstrate basic statistical descriptions for attributes of your choice (at least\n",
    "#two attributes, and at least one of each boxplot, histogram, quantile plot, boxplot,\n",
    "#quantile-quantile plot, scatterplot); explain any “useful” characteristics of those attributes\n",
    "#that you can draw from those statistical descriptions. \n",
    "\n",
    "#Not sure if directions indicted two expamples  per plot, so most plots have two exmaples\n",
    "#Also, you'll probably want to uncomment/comment one plot at a time\n",
    "\n",
    "#Histogram\n",
    "#Histogram allows us to tell relative occurres of crime in various neighborhoods and of various types of crimes\n",
    "fiveOne = crimeSet.copy()\n",
    "fiveOne[\"Description\"] = fiveOne[\"Description\"].astype('category').cat.codes\n",
    "fiveOne[\"Neighborhood\"] = fiveOne[\"Neighborhood\"].astype('category').cat.codes \n",
    "\n",
    "#fiveOne.hist(column=\"Description\")\n",
    "#fiveOne.hist(column=\"Neighborhood\")\n",
    "\n",
    "\n",
    "#BoxPlot\n",
    "#Boxplots gives us a look at the outliers and other statistical info (Mean, median, std etc)\n",
    "#for crime neighborhoods and types in baltimore\n",
    "#fiveOne.boxplot(column=\"Description\",return_type='axes')\n",
    "#fiveOne.boxplot(column=\"Neighborhood\",return_type='axes')\n",
    "\n",
    "\n",
    "#Scatterplot\n",
    "#Scatter plot of xy why location gives a relative positin for vacanies.\n",
    "#we could overlay this to google maps to find exact locations of vacancies\n",
    "fiveTwo = vacantSet.copy()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for a in vacantSet[\"Location\"][0:100]:\n",
    "    junction = a.split(\" \")\n",
    "    x.append( junction[0][1:len(junction[0]) - 1 ])\n",
    "    y.append( float(junction[1][0:len(junction[1]) - 1 ]))\n",
    "\n",
    "#plt.scatter(x, y)\n",
    "#plt.show()\n",
    "\n",
    "#Quantile Plot\n",
    "#Quantile plot gives us the 25, 50 and 75 percetn quantiles for crime types and across all neighborhood combines\n",
    "quantiles = mstats.mquantiles(fiveOne[\"Description\"])\n",
    "\n",
    "#for  q in enumerate(quantiles):\n",
    "#   plt.plot(q, label=labels[i])\n",
    "\n",
    "#quantiles = mstats.mquantiles(fiveOne[\"Neighborhood\"])\n",
    "\n",
    "#for  q in enumerate(quantiles):\n",
    "#   plt.plot(q, label=labels[i])\n",
    "\n",
    "#Quantile-Quantile Plot\n",
    "#QQ lets us analyyze if these two data sets have a common distribution, helpful especially for determining\n",
    "# correlations beteen crime and vacanies or between  other attribrutes\n",
    "  \n",
    "#stats.probplot(fiveOne[\"Neighborhood\"], dist=\"norm\", plot=pylab)\n",
    "#pylab.show()\n",
    "\n",
    "#stats.probplot(fiveOne[\"Description\"], dist=\"norm\", plot=pylab)\n",
    "#pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CrimeDate  CrimeCode                    Location  Description  \\\n",
      "0       10/14/2017         38          2700 BEETHOVEN AVE            0   \n",
      "1       10/14/2017         42          4200 EDMONDSON AVE            5   \n",
      "2       10/14/2017         42  BALTIMORE ST & N HOWARD ST            5   \n",
      "3       10/14/2017         42  BALTIMORE ST & N HOWARD ST            5   \n",
      "4       10/14/2017         42          400 WALTON AV, AAC            5   \n",
      "5       10/14/2017         80               900 N EDEN ST           14   \n",
      "6       10/14/2017         80             1400 CARROLL ST           14   \n",
      "7       10/14/2017         80             1400 CARROLL ST           14   \n",
      "8       10/14/2017         80             200 S DALLAS CT           14   \n",
      "9       10/14/2017          6        500 N CARROLLTON AVE           10   \n",
      "10      10/14/2017         38               900 N EDEN ST            0   \n",
      "11      10/14/2017         28             1000 HERNDON CT           12   \n",
      "12      10/14/2017         42          1800 N CAROLINE ST            5   \n",
      "13      10/14/2017          5             1400 CARROLL ST           13   \n",
      "14      10/14/2017          6              400 S MACON ST           10   \n",
      "15      10/14/2017         42           2400 E FEDERAL ST            5   \n",
      "16      10/14/2017         52        2700 WASHINGTON BLVD            7   \n",
      "17      10/14/2017         11         ST & S PRESIDENT ST           13   \n",
      "18      10/14/2017         11         ST & S PRESIDENT ST           13   \n",
      "19      10/14/2017         11         ST & S PRESIDENT ST           13   \n",
      "20      10/14/2017         11            700 ALICEANNA ST           13   \n",
      "21      10/14/2017         42                 900 FAWN ST            5   \n",
      "22      10/14/2017         52               600 W 33RD ST            7   \n",
      "23      10/14/2017         61             3400 HARFORD RD            3   \n",
      "24      10/14/2017         43           4800 BEAUFORT AVE            2   \n",
      "25      10/14/2017         38        2700 WASHINGTON BLVD            0   \n",
      "26      10/14/2017         42         5100 LITCHFIELD AVE            5   \n",
      "27      10/14/2017         42             400 S GILMOR ST            5   \n",
      "28      10/14/2017         52          2200 E MONUMENT ST            7   \n",
      "29      10/14/2017         52        2700 WASHINGTON BLVD            7   \n",
      "...            ...        ...                         ...          ...   \n",
      "282719    1/1/2012         43               600 OLDHAM ST            2   \n",
      "282720    1/1/2012         53          5600 LOCH RAVEN BD            8   \n",
      "282721    1/1/2012         42          1200 W SARATOGA ST            5   \n",
      "282722    1/1/2012         42            300 ILCHESTER AV            5   \n",
      "282723    1/1/2012         39            100 W JEFFREY ST            0   \n",
      "282724    1/1/2012         39             2200 EASTERN AV            0   \n",
      "282725    1/1/2012         54            2100 AISQUITH ST            7   \n",
      "282726    1/1/2012         44             1800 LETITIA AV            4   \n",
      "282727    1/1/2012         53          2800 E NORTHERN PW            8   \n",
      "282728    1/1/2012         56           2800 E MADISON ST            7   \n",
      "282729    1/1/2012         47            300 BROADMOOR RD            4   \n",
      "282730    1/1/2012         54             1100 N MACON ST            7   \n",
      "282731    1/1/2012         47               500 RADNOR AV            4   \n",
      "282732    1/1/2012         77              3400 DUVALL AV            1   \n",
      "282733    1/1/2012         52                0 E NORTH AV            7   \n",
      "282734    1/1/2012         56              600 S BROADWAY            7   \n",
      "282735    1/1/2012         42              600 N BROADWAY            5   \n",
      "282736    1/1/2012         42              3400 ELMLEY AV            5   \n",
      "282737    1/1/2012         42           1100 S CHARLES ST            5   \n",
      "282738    1/1/2012         40           1200 W LOMBARD ST            0   \n",
      "282739    1/1/2012         61             4400 PARKTON ST            3   \n",
      "282740    1/1/2012         44             900 QUANTRIL WY            4   \n",
      "282741    1/1/2012         44               1700 EUTAW PL            4   \n",
      "282742    1/1/2012         46                 2500 ALBIAN            4   \n",
      "282743    1/1/2012         63           1600 CLIFTVIEW AV            3   \n",
      "282744    1/1/2012         58                1400 JOH AVE            7   \n",
      "282745    1/1/2012         58            5500 SINCLAIR LN            7   \n",
      "282746    1/1/2012         54       400 N PATTERSON PK AV            7   \n",
      "282747    1/1/2012         44             5800 LILLYAN AV            4   \n",
      "282748    1/1/2012         44           1900 GRINNALDS AV            4   \n",
      "\n",
      "        Weapon      District  Neighborhood  \n",
      "0            0  NORTHWESTERN            -1  \n",
      "1            1  SOUTHWESTERN           218  \n",
      "2            1       CENTRAL            62  \n",
      "3            1       CENTRAL            62  \n",
      "4            1       CENTRAL           249  \n",
      "5            0       EASTERN           182  \n",
      "6            0      SOUTHERN           256  \n",
      "7            0      SOUTHERN           256  \n",
      "8            0  SOUTHEASTERN           202  \n",
      "9            0       WESTERN           108  \n",
      "10           0       EASTERN           182  \n",
      "11          -1      SOUTHERN            26  \n",
      "12           1       EASTERN           183  \n",
      "13           0      SOUTHERN           256  \n",
      "14           0  SOUTHEASTERN            97  \n",
      "15           1       EASTERN            24  \n",
      "16          -1  SOUTHWESTERN           166  \n",
      "17          -1  SOUTHEASTERN           123  \n",
      "18          -1  SOUTHEASTERN           123  \n",
      "19          -1  SOUTHEASTERN           123  \n",
      "20          -1  SOUTHEASTERN           123  \n",
      "21           1  SOUTHEASTERN           140  \n",
      "22          -1      NORTHERN           274  \n",
      "23          -1  NORTHEASTERN           150  \n",
      "24          -1  NORTHWESTERN            42  \n",
      "25           0  SOUTHWESTERN           166  \n",
      "26           1  NORTHWESTERN            42  \n",
      "27           1      SOUTHERN           174  \n",
      "28          -1       EASTERN           157  \n",
      "29          -1  SOUTHWESTERN           166  \n",
      "...        ...           ...           ...  \n",
      "282719      -1  SOUTHEASTERN            97  \n",
      "282720      -1  NORTHEASTERN           141  \n",
      "282721       1       WESTERN           206  \n",
      "282722       1      NORTHERN           109  \n",
      "282723       2      SOUTHERN            26  \n",
      "282724       2  SOUTHEASTERN           248  \n",
      "282725      -1       EASTERN            69  \n",
      "282726      -1  SOUTHWESTERN           166  \n",
      "282727      -1  NORTHEASTERN           261  \n",
      "282728      -1       EASTERN           149  \n",
      "282729      -1      NORTHERN           118  \n",
      "282730      -1       EASTERN           184  \n",
      "282731      -1      NORTHERN           268  \n",
      "282732      -1  NORTHWESTERN           107  \n",
      "282733      -1       CENTRAL            43  \n",
      "282734      -1  SOUTHEASTERN            83  \n",
      "282735       1       EASTERN            66  \n",
      "282736       1  NORTHEASTERN            11  \n",
      "282737       1      SOUTHERN            82  \n",
      "282738       3      SOUTHERN           117  \n",
      "282739      -1  SOUTHWESTERN           276  \n",
      "282740      -1  NORTHEASTERN             4  \n",
      "282741      -1       CENTRAL            20  \n",
      "282742      -1  NORTHEASTERN           137  \n",
      "282743      -1       EASTERN            58  \n",
      "282744      -1  SOUTHWESTERN           251  \n",
      "282745      -1  NORTHEASTERN            87  \n",
      "282746      -1       EASTERN            29  \n",
      "282747      -1  NORTHEASTERN            95  \n",
      "282748      -1  SOUTHWESTERN           166  \n",
      "\n",
      "[282749 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#4. [10 pts] Use any two methods of your choice to convert non-numeric attributes of interest\n",
    "#into numeric ones. (eg. one hot encoding, etc) \n",
    "\n",
    "#Method 1: one hot encoding \n",
    "\n",
    "fiveOne = crimeSet.copy()\n",
    "#we can either print out the dummies(the vector forms)...\n",
    "\n",
    "#print(pandas.get_dummies(fiveOne[\"CrimeCode\"]))\n",
    "#print(pandas.get_dummies(fiveOne[\"Description\"]))\n",
    "#print(fiveOne[\"CrimeCode\"] = pandas.get_dummies(fiveOne[\"Weapon\"]))\n",
    "#print(pandas.get_dummies(fiveOne[\"Neighborhood\"]))\n",
    "\n",
    "#Method 2: Label Encoding\n",
    "#or  Overlay them into the original panda (this time in encoded form) and then print the entire panda\n",
    "fiveOne = crimeSet.copy()\n",
    "fiveOne[\"CrimeCode\"] = fiveOne[\"CrimeCode\"].astype('category').cat.codes\n",
    "fiveOne[\"Description\"] = fiveOne[\"Description\"].astype('category').cat.codes\n",
    "fiveOne[\"Weapon\"] = fiveOne[\"Weapon\"].astype('category').cat.codes\n",
    "fiveOne[\"Neighborhood\"] = fiveOne[\"Neighborhood\"].astype('category').cat.codes\n",
    "print(fiveOne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#5. [20 pts] Demonstrate two techniques for handling missing data on attributes of your\n",
    "#choice\n",
    "\n",
    "#Method 1: ignore values : done by droping any rows with Nan values.\n",
    "fiveOne = crimeSet.copy()\n",
    "#print (fiveOne)\n",
    "fiveOne = fiveOne.dropna(axis=0, how = 'any')\n",
    "#print (fiveOne)\n",
    "\n",
    "#Method 2: chnage to a global constant: one (intuitive) identifier per column.\n",
    "fiveOne = crimeSet.copy()\n",
    "fiveOne [\"CrimeDate\"].fillna(value=\"No Data\",inplace = True)\n",
    "fiveOne [\"CrimeCode\"].fillna(value=\"No Data\",inplace = True)\n",
    "fiveOne [\"Location\"].fillna(value=\"Baltimore\",inplace = True)\n",
    "fiveOne [\"Description\"].fillna(value=\"No Description\",inplace = True)\n",
    "fiveOne [\"Weapon\"].fillna(value=\"No Weapon\",inplace = True)\n",
    "fiveOne [\"Neighborhood\"].fillna(value=\"General\",inplace = True)\n",
    "#print (fiveOne)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6. [20 pts] Examine two attributes of interest for potential outliers. Show the steps in your\n",
    "#examination and reasoning\n",
    "\n",
    "#Let's first start with a quick way. And he's what's cool. We've already found it before. By using histograms,\n",
    "# we can inspect attributes for potiential outliers. Either too few or an absurdly large abount of attributes.\n",
    "#While we'd probably want to use labelling featuresto label each bar, we'll skip that for now in place of showing that\n",
    "#This is a valid and quick way of looking for outlines within attributes.\n",
    "\n",
    "fiveOne = crimeSet.copy()\n",
    "fiveOne[\"District\"] = fiveOne[\"District\"].astype('category').cat.codes\n",
    "fiveOne[\"Weapon\"] = fiveOne[\"Weapon\"].astype('category').cat.codes\n",
    "\n",
    "#fiveOne.hist(column=\"Neighborhood\")\n",
    "\n",
    "#fiveOne.hist(column=\"Weapon\")\n",
    "\n",
    "\n",
    "#Now's let's go for a bit more of a  traditional approach. \n",
    "#If we wanted to look for outliers in crime types or in neighborhood occurance, we could print out the frequency of occurence\n",
    "#of each attribute and then also look at statistical data to drive home the variances. \n",
    "#We see a great many outliers in the crimes between spome neighborhoods, even without the standard deviation telling us.\n",
    "#Theres also a relative low amount of arsons in the descriptions frequency counts.\n",
    "\n",
    "crime_freqs = crimeSet[\"Description\"].value_counts()\n",
    "#print(crime_freqs)\n",
    "#print(crime_freqs.mean(0))\n",
    "#print(crime_freqs.median(0))\n",
    "#print(crime_freqs.std(0))\n",
    "\n",
    "\n",
    "crime_freqs = crimeSet[\"Neighborhood\"].value_counts()\n",
    "#print(crime_freqs)\n",
    "#print(crime_freqs.mean(0))\n",
    "#print(crime_freqs.median(0))\n",
    "#print(crime_freqs.std(0))\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#7. [20 pts] Demonstrate a technique for examining the “noise” in a data attribute of your\n",
    "#choice and how to “denoise” it.\n",
    "\n",
    "#While none of our data looks like it's been entered inproperly or may be incredibly noisy, some of the entry for our data makes it hard for \n",
    "#us to represent it, and in a preprosessing sense, that would definatively tranlate to noise\n",
    "\n",
    "# if we take a look at the Vacancy data, we see that some vacancies occur on nearly the same block and lot,\n",
    "#distingished alphabetically so say 21A and  21B. While this may make sense in the content of urban planning, \n",
    "#this data hinders us from being able to represent our lot values in a fully numeric sense for say, \n",
    "#graphing purposes or statistical purposes.  If we wanted to see how many blocks had a vacancy on their 21'st lot,\n",
    "#but had a lot with further split units : 21 A and 21B, it would be tedious to try to indicate that \"half\n",
    "# or even a quarter of the houses on the lot has been vacated\"\n",
    "# We have a few options for denoising this noise, One would be to count each subhouse as its own  unit (which may be \n",
    "#close to real life since they may have separate families living in them) ,\n",
    "#but in this case, we'll simply fully remove the noise from the system delete them, which is a completely valid solution \n",
    "#for \"denoising data\" any entries with nonnumeric noisy entirees.\n",
    "\n",
    "#We'll start by converting all of our lot values into numeric elements. Our numberic-alphabetic hybric will become NaN\n",
    "#Then, we'll add an additional filter to drop all\n",
    "fiveOne = vacantSet.copy()\n",
    "fiveOne[\"Lot\"] = fiveOne[\"Lot\"].convert_objects(convert_numeric=True).dropna()\n",
    "\n",
    "\n",
    "#There! Now we have full numeric values in place for our Lots\n",
    "#print(fiveOne) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#8. [20 pts] Demonstrate the creation for two new attributes from existing attributes that\n",
    "#would be useful in a preliminary assessment of dependency between crimes and\n",
    "#building vacancies.\n",
    "\n",
    "#Lets say that we dont know if crime is depened on vacancies or vacancies are dependent on crimes. \n",
    "#Our attributes will count how many vacancies have occurred in a neighborhood of a crime leading up to the crime\n",
    "#how many crimes have occured in a neighborhood of a vacancies, leading up to the vacancy.\n",
    "#We need to check that  the denpend occurs before the independent and that they occur in the same neighborhood.\n",
    "#In this problem, I  use a sample of the crime and vacancy set since you most\n",
    "#loop through both to create the attribute. THough i have code to add the full attribute to the panda\n",
    "#I'd advise not trying to wait for the compilation of both of these. You'll see a vector that increases as crime/vacancies \n",
    "#are looped through. \n",
    "#THe second one takes a bit more time because it goes back to 1992 and one of the sets are grossly larger than the other\n",
    "#play around with the indicies to see interesting results, but I can verify that this does work.\n",
    "\n",
    "\n",
    "vacanciesSinceCrime = []\n",
    "for rowC in crimeSet[0:1000].itertuples(index=True):\n",
    "    vacanciesSinceCrimeCount = 0\n",
    "    crimeDate = time.strptime(rowC[1], \"%m/%d/%Y\")\n",
    "    for rowV in vacantSet[0:1000].itertuples(index=True):\n",
    "        vacantDate = time.strptime(rowV[5], \"%m/%d/%Y\")\n",
    "        \n",
    "        if crimeDate > vacantDate and rowV[6] == rowC[7]:\n",
    "            vacanciesSinceCrimeCount += 1\n",
    "        \n",
    "    vacanciesSinceCrime.append(vacanciesSinceCrimeCount)\n",
    "    #print(vacanciesSinceCrime)\n",
    "\n",
    "#print( vacanciesSinceCrime)\n",
    "#crimeSet[\"Vacancies in Neighborhood before Crime\"] = vacanciesSinceCrime    \n",
    "    \n",
    "#print(crimeSet)\n",
    "\n",
    "crimesinceVacancies = []\n",
    "for rowV in vacantSet[10000:20000].itertuples(index=True):\n",
    "    crimesinceVacanciesCount = 0\n",
    "    vacantDate  = time.strptime(rowV[5], \"%m/%d/%Y\")\n",
    "    for rowC in crimeSet[0:100].itertuples(index=True):\n",
    "        crimeDate = time.strptime(rowC[1], \"%m/%d/%Y\")\n",
    "        \n",
    "        if crimeDate < vacantDate and rowV[6] == rowC[7]:\n",
    "            crimesinceVacanciesCount += 1\n",
    "    crimesinceVacancies.append(crimesinceVacanciesCount)\n",
    "    #print(crimesinceVacancies)\n",
    "    \n",
    "#print(crimesinceVacancies)\n",
    "#vacantSet[\"Crimes in Neighborhood before Vancancy\"] = crimesinceVacancies\n",
    "\n",
    "#print(vacantSet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#9. [20 pts] Demonstrate how to reduce numerosity (#distinct values) of an attribute of your\n",
    "#choice using binning; discuss your approach and other choices. \n",
    "\n",
    "#Let's say we want to look at gun laws and gun policy in baltimore instead of vacanies and crime. This set would still be \n",
    "#useful, but it'd be really helpful to break  our data intpo this into crimes that occure with guns, \n",
    "#vs crimes that occure without. We'll also dump all crimes that have no weapons to make our search easier\n",
    "\n",
    "#Some other choice, primarily would be to base this around years. We could use important dates, like the milestones in\n",
    "#the electon cycle, record temperature dates or the date of freddie gray's murder as markers and bins to base\n",
    "#crime occurrences around.\n",
    "\n",
    "fiveOne = crimeSet.copy()\n",
    "fiveOne = fiveOne.dropna()\n",
    "\n",
    "fiveOne[\"Weapon\"] = fiveOne[\"Weapon\"].astype('category').cat.codes\n",
    "data = [-1,.9,5]\n",
    "bins  = ['Handgun Crime',\"Not Hangun Crime\" ]\n",
    "\n",
    "fiveOne[\"Weapon\"] = pandas.cut(fiveOne[\"Weapon\"], data, labels=bins)\n",
    "#print(fiveOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#10. [20 pts] Fuse/join information from the two datasets (crime and vacancies) into a new\n",
    "#panda.\n",
    "#Let's ad number of vacanies into the crime dates, based around time and if they occurr in the same neighborhood. \n",
    "# THis would be helpful for finding correlations.\n",
    "\n",
    "\n",
    "fiveOne = vacantSet.copy()\n",
    "vacsinNeighborhood = []\n",
    "\n",
    "for rowC in crimeSet[0:50].itertuples(index=True):\n",
    "        crimeDate = time.strptime(rowC[1], \"%m/%d/%Y\")\n",
    "        vacs = 0\n",
    "\n",
    "        for rowV in vacantSet[0:5000].itertuples(index=True):\n",
    "            vacantDate  = time.strptime(rowV[5], \"%m/%d/%Y\")\n",
    "   \n",
    "        \n",
    "            if vacantDate <= crimeDate and  rowV[6] == rowC[7]:\n",
    "                vacs += 1\n",
    "                \n",
    "        vacsinNeighborhood.append(vacs) \n",
    "\n",
    "demo = crimeSet[0:50]  \n",
    "demo['Vacancies in Neighborhood'] = vacsinNeighborhood\n",
    "#print (demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#11. [20 pts] Demonstrate data reduction using sampling techniques on subsets of attributes\n",
    "#of your (demonstrate sampling with and without replacement, stratified and un-stratified;\n",
    "#4 total combinations); \n",
    "\n",
    "#Math and Probability examples here\n",
    "#While I won't do this here, as I've already taken Statistics, you can calulate the probability \n",
    "#if randomingly chosing and entry  that has an arson crime to a discrete possibility. That possibility is the same if after it is\n",
    "#picked, you pick again with replacement, changes if no replacement and you either pick an arson crime or not and\n",
    "#potentially increases if you break our data into stata around its district.  I'll leav you to play with those \n",
    "#probabilites. Ypu could also replace description with weapon, or date. Take number of desired instances ove number of total\n",
    "#instances to choose from for the basic case, and  go from there dependign on if you replace or break into 9 stata with \n",
    "#9 seprarte picks\n",
    "fiveOne = crimeSet.copy()\n",
    "\n",
    "#A. Unstrastisfied, With Replacement\n",
    "results = fiveOne.sample(n=1,replace=True)\n",
    "#print(results)\n",
    "results = fiveOne.sample(n=100,replace=True)\n",
    "#print(results)\n",
    "\n",
    "\n",
    "#B. Unstrastisfied, No replacement\n",
    "results = fiveOne.sample(n=1,replace=False)\n",
    "#print(results)\n",
    "results = fiveOne.sample(n=100,replace=False)\n",
    "#print(results)\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "#C. Unstrastisfied, With Replacement\n",
    "\n",
    "eastern = fiveOne.where(fiveOne['District'] == 'EASTERN').dropna()\n",
    "northern = fiveOne.where(fiveOne['District'] == 'NORTHERN').dropna()\n",
    "western = fiveOne.where(fiveOne['District'] == 'WESTERN').dropna()\n",
    "southern = fiveOne.where(fiveOne['District'] == 'SOUTHERN').dropna()\n",
    "southeastern = fiveOne.where(fiveOne['District'] == 'SOUTHEASTERN').dropna()\n",
    "southwestern = fiveOne.where(fiveOne['District'] == 'SOUTHWESTERN').dropna()\n",
    "northwestern = fiveOne.where(fiveOne['District'] == 'NORTHWESTERN').dropna()\n",
    "northeastern = fiveOne.where(fiveOne['District'] == 'NORTHEASTERN').dropna()\n",
    "central = fiveOne.where(fiveOne['District'] == 'CENTRAL').dropna()\n",
    "\n",
    "results = eastern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "northern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "western.sample(n=1,replace=True)\n",
    "print(results)\n",
    "southern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "southeastern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "southwestern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "northwestern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "northeastern.sample(n=1,replace=True)\n",
    "print(results)\n",
    "central.sample(n=1,replace=True)\n",
    "print(results)\n",
    "\n",
    "#~~~~\n",
    "\n",
    "results = eastern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "northern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "western.sample(n=100,replace=True)\n",
    "print(results)\n",
    "southern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "southeastern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "southwestern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "northwestern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "northeastern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "central.sample(n=100,replace=True)\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#D. Strastisfied, No Replacement\n",
    "   \n",
    "fiveOne['District'] = fiveOne['District'].astype('str') \n",
    "\n",
    "eastern = fiveOne.where(fiveOne['District'] == 'EASTERN').dropna()\n",
    "northern = fiveOne.where(fiveOne['District'] == 'NORTHERN').dropna()\n",
    "western = fiveOne.where(fiveOne['District'] == 'WESTERN').dropna()\n",
    "southern = fiveOne.where(fiveOne['District'] == 'SOUTHERN').dropna()\n",
    "southeastern = fiveOne.where(fiveOne['District'] == 'SOUTHEASTERN').dropna()\n",
    "southwestern = fiveOne.where(fiveOne['District'] == 'SOUTHWESTERN').dropna()\n",
    "northwestern = fiveOne.where(fiveOne['District'] == 'NORTHWESTERN').dropna()\n",
    "northeastern = fiveOne.where(fiveOne['District'] == 'NORTHEASTERN').dropna()\n",
    "central = fiveOne.where(fiveOne['District'] == 'CENTRAL').dropna()\n",
    "\n",
    "\n",
    "eastern.sample(n=1,replace=False)\n",
    "northern.sample(n=1,replace=False)\n",
    "western.sample(n=1,replace=False)\n",
    "southern.sample(n=1,replace=False)\n",
    "southeastern.sample(n=1,replace=False)\n",
    "southwestern.sample(n=1,replace=False)\n",
    "northwestern.sample(n=1,replace=False)\n",
    "northeastern.sample(n=1,replace=False)\n",
    "central.sample(n=1,replace=False)\n",
    "\n",
    "\n",
    "results = eastern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "northern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "western.sample(n=1,replace=False)\n",
    "print(results)\n",
    "southern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "southeastern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "southwestern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "northwestern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "northeastern.sample(n=1,replace=False)\n",
    "print(results)\n",
    "central.sample(n=1,replace=False)\n",
    "print(results)\n",
    "\n",
    "#~~~~\n",
    "\n",
    "results = eastern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "northern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "western.sample(n=100,replace=True)\n",
    "print(results)\n",
    "southern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "southeastern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "southwestern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "northwestern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "northeastern.sample(n=100,replace=True)\n",
    "print(results)\n",
    "central.sample(n=100,replace=True)\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#12. [20 pts] For two categorical attributes of your choice, demonstrate the contingency table\n",
    "#and conduct a chi-squared test of independence; explain your findings.\n",
    "\n",
    "#lets see if we can find a correlation betwen the district and the type of crime.\n",
    "#maybe some people are more likely to steal at the inner harbor?\n",
    "#Low chi squared are low values and our table counts our instances and gives us an idea of how many times\n",
    "#instances have occured in certain neighborhoods.\n",
    "fiveOne = crimeSet.copy()\n",
    "b = pandas.crosstab(fiveOne[\"Description\"], fiveOne[\"District\"], margins=True)\n",
    "b = b.drop(['All'])\n",
    "b = b.drop('All', axis=1)\n",
    "\n",
    "print(b)\n",
    "scipy.stats.chisquare(b)\n",
    "\n",
    "#You can alos play around with crime types in certain Neighborhoods for a larger table\n",
    "\n",
    "#fiveOne = crimeSet.copy()\n",
    "#b = pandas.crosstab(fiveOne[\"Description\"], fiveOne[\"Neighborhood\"], margins=True)\n",
    "#b = b.drop(['All'])\n",
    "#b = b.drop('All', axis=1)\n",
    "#print(b)\n",
    "#scipy.stats.chisquare(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#13. [20 pts] For two numerical attributes of your choice, demonstrate the covariance matrix\n",
    "#compute their correlation coefficient; explain/interpret your findings.\n",
    "\n",
    "#Let's see if, for spome reason blocks and lots are correlated.\n",
    "#Maybe certain lots are more likely to be target for crime and then therefore vacated. \n",
    "#Low corefficient, lor correlation, high for high. Table shows values like in #12 above.\n",
    "\n",
    "fiveOne = vacantSet.copy()\n",
    "#print(fiveOne)\n",
    "fiveOne = fiveOne.drop('PoliceDistrict' ,axis=1)\n",
    "fiveOne = fiveOne.drop('NoticeDate', axis=1)\n",
    "fiveOne = fiveOne.drop('Location', axis=1)\n",
    "fiveOne = fiveOne.drop('BuildingAddress', axis=1)\n",
    "fiveOne = fiveOne.drop('ReferenceID', axis=1)\n",
    "fiveOne = fiveOne.drop('Neighborhood', axis=1)\n",
    "fiveOne = fiveOne.drop('CouncilDistrict', axis=1)\n",
    "#print( fiveOne)\n",
    "\n",
    "fiveOne[\"Block\"] = fiveOne[\"Block\"].convert_objects(convert_numeric=True).dropna()\n",
    "fiveOne[\"Lot\"] = fiveOne[\"Lot\"].convert_objects(convert_numeric=True).dropna()\n",
    "#print(fiveOne.cov())\n",
    "\n",
    "\n",
    "#fiveOne['Block'].corr(fiveOne['Lot'])\n",
    "\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
